{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertConfig, BertPreTrainedModel\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sentencepiece\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/merrick/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset/cnn_dailymail/train.csv\", nrows=1000)\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
       "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
       "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A drunk driver who killed a young woman in a h...</td>\n",
       "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
       "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fleetwood are the only team still to have a 10...</td>\n",
       "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
       "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
       "2  A drunk driver who killed a young woman in a h...   \n",
       "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
       "4  Fleetwood are the only team still to have a 10...   \n",
       "\n",
       "                                                   y  \n",
       "0  Bishop John Folda, of North Dakota, is taking ...  \n",
       "1  Criminal complaint: Cop used his role to help ...  \n",
       "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
       "3  Nina dos Santos says Europe must be ready to a...  \n",
       "4  Fleetwood top of League One after 2-0 win at S...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## keep the first N articles if you want to keep it lite \n",
    "dtf = pd.DataFrame(dataset).rename(columns={\"article\":\"text\", \n",
    "      \"highlights\":\"y\"})[[\"text\",\"y\"]]\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_preprocess_text(txt, punkt=True, lower=True, slang=True, lst_stopwords=None, stemm=False, lemm=True):\n",
    "    ### separate sentences with '. '\n",
    "    txt = re.sub(r'\\.(?=[^ \\W\\d])', '. ', str(txt))\n",
    "    ### remove punctuations and characters\n",
    "    txt = re.sub(r'[^\\w\\s]', '', txt) if punkt is True else txt\n",
    "    ### strip\n",
    "    txt = \" \".join([word.strip() for word in txt.split()])\n",
    "    ### lowercase\n",
    "    txt = txt.lower() if lower is True else txt\n",
    "    ### slang\n",
    "    txt = contractions.fix(txt) if slang is True else txt   \n",
    "    ### tokenize (convert from string to list)\n",
    "    lst_txt = txt.split()\n",
    "    ### stemming (remove -ing, -ly, ...)\n",
    "    if stemm is True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_txt = [ps.stem(word) for word in lst_txt]\n",
    "    ### lemmatization (convert the word into root word)\n",
    "    if lemm is True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_txt = [lem.lemmatize(word) for word in lst_txt]\n",
    "    ### remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_txt = [word for word in lst_txt if word not in \n",
    "                   lst_stopwords]\n",
    "    ### back to string\n",
    "    txt = \" \".join(lst_txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text\n",
    "dtf[\"text\"] = dtf[\"text\"].apply(lambda x: utils_preprocess_text(x))\n",
    "dtf[\"y\"] = dtf[\"y\"].apply(lambda x: utils_preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text in the DataFrame\n",
    "dtf['text'] = dtf['text'].apply(lambda x: tokenizer.encode(x, return_tensors='pt'))\n",
    "\n",
    "# Tokenize the target summaries if applicable\n",
    "dtf['y'] = dtf['y'].apply(lambda x: tokenizer.encode(x, return_tensors='pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2011,  3378,  2811,  2405, 15471,  2487,  9765,  2423,  2255,\n",
      "          2286,  7172, 16710,  2575,  9765,  2423,  2255,  2286,  1996,  3387,\n",
      "          1997,  1996, 23054,  3234,  5801,  1999,  2167,  7734,  5292,  6086,\n",
      "          9280,  3634,  1997,  2277,  2266,  1999, 23054,  2882,  9292,  1998,\n",
      "         27435,  2000,  1996, 28389,  1037,  7865,  1999,  2397,  2244,  1998,\n",
      "          2220,  2255,  1996,  2110,  2740,  2533,  5292,  3843,  2019,  7319,\n",
      "          1997,  7524,  2005,  3087,  2040,  3230,  2274,  2277,  1998,  2165,\n",
      "         15661,  3387,  2198, 10671,  2050, 15885,  1997,  1996, 23054,  3234,\n",
      "          5801,  1999,  2167,  7734,  5292,  6086,  9280,  3634,  1997,  2277,\n",
      "          2266,  1999, 23054,  2882,  9292,  1998, 27435,  2000,  1996, 28389,\n",
      "          1037,  2110, 10047, 23041,  3989,  2565,  3208,  9618, 18473,  2360,\n",
      "          1996,  3891,  2003,  2659,  2021,  2880,  2514,  2009,  2590,  2000,\n",
      "          9499,  2111,  2000,  1996,  2825,  7524,  1996,  5801,  2623,  2006,\n",
      "          6928,  2008,  3387,  2198, 10671,  2050,  2003,  2635,  2051,  2125,\n",
      "          2044,  2108, 11441,  2007, 28389,  1037,  1996,  5801,  2360,  2002,\n",
      "         11016,  1996,  8985,  2083, 19450,  2833,  2096,  7052,  1037,  3034,\n",
      "          2005,  4397,  9492,  3387,  1999,  3304,  2197,  3204, 25353, 27718,\n",
      "          5358,  1997, 28389,  1037,  2421,  9016,  5458,  2791,  3279,  1997,\n",
      "         18923, 19029,  1998, 21419, 17964, 23054,  3234,  5801,  1999,  2167,\n",
      "          7734, 15885,  2003,  2073,  1996,  3387,  2003,  2284,   102]])\n"
     ]
    }
   ],
   "source": [
    "print(dtf[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dtf):\n",
    "        self.dtf = dtf\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dtf)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dtf[idx]\n",
    "\n",
    "# Instantiate your custom dataset with the tokenized data\n",
    "dataset = CustomDataset(dtf)\n",
    "\n",
    "# Create a DataLoader with appropriate batch size, shuffle, and other options\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x2af114f90>\n"
     ]
    }
   ],
   "source": [
    "print(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26229b7defef422e8f610f97bfda4c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
